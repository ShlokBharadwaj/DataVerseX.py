{"cells":[{"cell_type":"markdown","metadata":{"id":"jpsxhP9Dr5Af"},"source":["# Task 1 - Exploratory Data Analysis\n","\n","This notebook will walk you through this task interactively, meaning that once you've imported this notebook into `Google Colab`, you'll be able to run individual cells of code independantly, and see the results as you go.\n","\n","To follow along, simply read the notes within the notebook and run the cells in order.\n","\n","---\n","\n","## Section 1 - Setup\n","\n","First, we need to mount this notebook to our Google Drive folder, in order to access the CSV data file. If you haven't already, watch this video https://www.youtube.com/watch?v=woHxvbBLarQ to help you mount your Google Drive folder."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1850,"status":"ok","timestamp":1651932201587,"user":{"displayName":"Arun Godwin Patel","userId":"00651807189384869925"},"user_tz":-60},"id":"rYuqKbngqhNP","outputId":"6cb7d7ad-efcf-4a4a-cef2-030078766df7"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"rgaQP4eos9jS"},"source":["In order to view, analyse and manipulate the dataset, we must load it into something called a `dataframe`, which is a way of storing tabulated data in a virtual table. This dataframe will allow us to analyse the data freely. To load it into a dataframe, we will need a package called `Pandas`. We can install pandas with this command:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4471,"status":"ok","timestamp":1651932206055,"user":{"displayName":"Arun Godwin Patel","userId":"00651807189384869925"},"user_tz":-60},"id":"u5x18BTjqy3o","outputId":"f9fc08b8-50f8-4e86-a8ba-e7fc0a1f9674"},"outputs":[],"source":["%pip install pandas"]},{"cell_type":"markdown","metadata":{"id":"Ur2OdJMttaGP"},"source":["And now we can import this package like so:"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"_SP0zwPYq-ef"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>transaction_id</th>\n","      <th>timestamp</th>\n","      <th>product_id</th>\n","      <th>category</th>\n","      <th>customer_type</th>\n","      <th>unit_price</th>\n","      <th>quantity</th>\n","      <th>total</th>\n","      <th>payment_type</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>a1c82654-c52c-45b3-8ce8-4c2a1efe63ed</td>\n","      <td>2022-03-02 09:51:38</td>\n","      <td>3bc6c1ea-0198-46de-9ffd-514ae3338713</td>\n","      <td>fruit</td>\n","      <td>gold</td>\n","      <td>3.99</td>\n","      <td>2</td>\n","      <td>7.98</td>\n","      <td>e-wallet</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>931ad550-09e8-4da6-beaa-8c9d17be9c60</td>\n","      <td>2022-03-06 10:33:59</td>\n","      <td>ad81b46c-bf38-41cf-9b54-5fe7f5eba93e</td>\n","      <td>fruit</td>\n","      <td>standard</td>\n","      <td>3.99</td>\n","      <td>1</td>\n","      <td>3.99</td>\n","      <td>e-wallet</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>ae133534-6f61-4cd6-b6b8-d1c1d8d90aea</td>\n","      <td>2022-03-04 17:20:21</td>\n","      <td>7c55cbd4-f306-4c04-a030-628cbe7867c1</td>\n","      <td>fruit</td>\n","      <td>premium</td>\n","      <td>0.19</td>\n","      <td>2</td>\n","      <td>0.38</td>\n","      <td>e-wallet</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>157cebd9-aaf0-475d-8a11-7c8e0f5b76e4</td>\n","      <td>2022-03-02 17:23:58</td>\n","      <td>80da8348-1707-403f-8be7-9e6deeccc883</td>\n","      <td>fruit</td>\n","      <td>gold</td>\n","      <td>0.19</td>\n","      <td>4</td>\n","      <td>0.76</td>\n","      <td>e-wallet</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>a81a6cd3-5e0c-44a2-826c-aea43e46c514</td>\n","      <td>2022-03-05 14:32:43</td>\n","      <td>7f5e86e6-f06f-45f6-bf44-27b095c9ad1d</td>\n","      <td>fruit</td>\n","      <td>basic</td>\n","      <td>4.49</td>\n","      <td>2</td>\n","      <td>8.98</td>\n","      <td>debit card</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0                        transaction_id            timestamp  \\\n","0           0  a1c82654-c52c-45b3-8ce8-4c2a1efe63ed  2022-03-02 09:51:38   \n","1           1  931ad550-09e8-4da6-beaa-8c9d17be9c60  2022-03-06 10:33:59   \n","2           2  ae133534-6f61-4cd6-b6b8-d1c1d8d90aea  2022-03-04 17:20:21   \n","3           3  157cebd9-aaf0-475d-8a11-7c8e0f5b76e4  2022-03-02 17:23:58   \n","4           4  a81a6cd3-5e0c-44a2-826c-aea43e46c514  2022-03-05 14:32:43   \n","\n","                             product_id category customer_type  unit_price  \\\n","0  3bc6c1ea-0198-46de-9ffd-514ae3338713    fruit          gold        3.99   \n","1  ad81b46c-bf38-41cf-9b54-5fe7f5eba93e    fruit      standard        3.99   \n","2  7c55cbd4-f306-4c04-a030-628cbe7867c1    fruit       premium        0.19   \n","3  80da8348-1707-403f-8be7-9e6deeccc883    fruit          gold        0.19   \n","4  7f5e86e6-f06f-45f6-bf44-27b095c9ad1d    fruit         basic        4.49   \n","\n","   quantity  total payment_type  \n","0         2   7.98     e-wallet  \n","1         1   3.99     e-wallet  \n","2         2   0.38     e-wallet  \n","3         4   0.76     e-wallet  \n","4         2   8.98   debit card  "]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","data = pd.read_csv(\"../sample_sales_data.csv\")\n","data.head()"]},{"cell_type":"markdown","metadata":{"id":"M5nmOA2Rtd2E"},"source":["---\n","\n","## Section 2 - Data loading\n","\n","Now that Google Drive is mounted, you can store the CSV file anywhere in your Drive and update the `path` variable below to access it within this notebook. Once we've updated the `path`, let's read this CSV file into a pandas dataframe and see what it looks like"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":337},"executionInfo":{"elapsed":27,"status":"ok","timestamp":1651932207034,"user":{"displayName":"Arun Godwin Patel","userId":"00651807189384869925"},"user_tz":-60},"id":"oDB-Ylm3q_wk","outputId":"4f6ca84a-baaf-4b36-94ae-339c0439ca12"},"outputs":[],"source":["path = \"/content/drive/MyDrive/Forage - Cognizant AI Program/Task 1/Resources/sample_sales_data.csv\"\n","df = pd.read_csv(path)\n","df.drop(columns=[\"Unnamed: 0\"], inplace=True, errors='ignore')\n","df.head()"]},{"cell_type":"markdown","metadata":{"id":"ZI-Q3zvsGWpl"},"source":["Using the `.head()` method allows us to see the top 5 (5 by default) rows within the dataframe. We can use `.tail()` to see the bottom 5. If you want to see more than 5 rows, simply enter a number into the parentheses, e.g. `head(10)` or `tail(10)`."]},{"cell_type":"markdown","metadata":{"id":"qaXaaIr5Hemv"},"source":["---\n","\n","## Section 3 - Descriptive statistics\n","\n","From just looking at the data, it is hard to get a feeling of what all the columns and rows mean. To gain an understanding of the dataset, let's first look at what columns and datatypes we have"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26,"status":"ok","timestamp":1651932207035,"user":{"displayName":"Arun Godwin Patel","userId":"00651807189384869925"},"user_tz":-60},"id":"2A8VDx_nHsd1","outputId":"10c6a495-d770-439f-cf3d-17a8456b3d6a"},"outputs":[],"source":["df.info()"]},{"cell_type":"markdown","metadata":{"id":"cjMuz8cAHvBf"},"source":["The `.info()` method creates a data description of the dataframe. It tells us:\n","\n","- How many rows (7829)\n","- How many columns (8)\n","- Column names\n","- How many values are non-null for each column\n","- The types of data contained within each column\n","- The size of the dataset loaded into memory (~550KB)\n","\n","Looking at the output of the `.info()` method, we can intepret each column as follows:\n","\n","- transaction_id = this is a unique ID that is assigned to each transaction\n","- timestamp = this is the datetime at which the transaction was made\n","- product_id = this is an ID that is assigned to the product that was sold. Each product has a unique ID\n","- category = this is the category that the product is contained within\n","- customer_type = this is the type of customer that made the transaction\n","- unit_price = the price that 1 unit of this item sells for\n","- quantity = the number of units sold for this product within this transaction\n","- total = the total amount payable by the customer\n","- payment_type = the payment method used by the customer\n","\n","It is also interesting to look at the datatypes. We can see that there are 3 different datatypes within this dataset:\n","\n","- object = this column contains categorical values\n","- float64 = this column contains floating point numerical values (i.e. decimal numbers)\n","- int64 = this column contains integer values (whole numbers)\n","\n","Now let's compute some descriptive statistics of the numeric columns:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1651932207036,"user":{"displayName":"Arun Godwin Patel","userId":"00651807189384869925"},"user_tz":-60},"id":"qS6Dg7usDSgT","outputId":"7f9b9a71-2d60-42aa-da73-fbb5d62f05c6"},"outputs":[],"source":["df.describe()"]},{"cell_type":"markdown","metadata":{"id":"N-krPtHdHNrh"},"source":["The `.describe()` method computes some descriptive statistics of the numerical columns, including:\n","\n","- count = count of how many unique values exist\n","- mean = mean average value of this column\n","- std = standard deviation\n","- min = minimum value\n","- 25% = lower quartile value\n","- 50% = median value\n","- 75% = upper quartile value\n","- max = maximum value\n","\n","---\n","\n","## Section 4 - Visualisation\n","\n","These statistics are useful, but they are better understood using visualisations. For visualisation, we will use the `seaborn` package, which makes it really easy to create visualisations from a dataframe. \n","\n","To use them, let's first install and then import it:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3821,"status":"ok","timestamp":1651932210833,"user":{"displayName":"Arun Godwin Patel","userId":"00651807189384869925"},"user_tz":-60},"id":"fT9DrY9RHMrd","outputId":"165b9625-bccc-418e-a1e6-f55a88d3e20d"},"outputs":[],"source":["%pip install seaborn"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"32RDb2C7KOpN"},"outputs":[],"source":["import seaborn as sns"]},{"cell_type":"markdown","metadata":{"id":"rNvl5rGeKv-h"},"source":["To analyse the dataset, below are snippets of code that you can use as helper functions to visualise different columns within the dataset. They include:\n","\n","- plot_continuous_distribution = this is to visualise the distribution of numeric columns\n","- get_unique_values = this is to show how many unique values are present within a column\n","- plot_categorical_distribution = this is to visualise the distribution of categorical columns"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AyUPE4QRKcYQ"},"outputs":[],"source":["def plot_continuous_distribution(data: pd.DataFrame = None, column: str = None, height: int = 8):\n","  _ = sns.displot(data, x=column, kde=True, height=height, aspect=height/5).set(title=f'Distribution of {column}');\n","\n","def get_unique_values(data, column):\n","  num_unique_values = len(data[column].unique())\n","  value_counts = data[column].value_counts()\n","  print(f\"Column: {column} has {num_unique_values} unique values\\n\")\n","  print(value_counts)\n","\n","def plot_categorical_distribution(data: pd.DataFrame = None, column: str = None, height: int = 8, aspect: int = 2):\n","  _ = sns.catplot(data=data, x=column, kind='count', height=height, aspect=aspect).set(title=f'Distribution of {column}');"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":601},"executionInfo":{"elapsed":1198,"status":"ok","timestamp":1651932212369,"user":{"displayName":"Arun Godwin Patel","userId":"00651807189384869925"},"user_tz":-60},"id":"ab7JETaqKD9J","outputId":"f15463e0-4050-4f6c-9090-2f7a1fdd2108"},"outputs":[],"source":["plot_continuous_distribution(df, 'unit_price')"]},{"cell_type":"markdown","metadata":{"id":"01lTNf6uLmyh"},"source":["This tell us that the distribution of `unit_price` is positively skewed, that is, there are more sales of products with a low unit_price compared to products with a high unit_price.\n","\n","This makes sense, you would expect a grocery store to sell more products that are cheap, and just a few products that are really expensive."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":601},"executionInfo":{"elapsed":1196,"status":"ok","timestamp":1651932213562,"user":{"displayName":"Arun Godwin Patel","userId":"00651807189384869925"},"user_tz":-60},"id":"Qb8-aZq6KT7h","outputId":"27eb29ce-9c31-4f65-906a-3a0cfa343afc"},"outputs":[],"source":["plot_continuous_distribution(df, 'quantity')"]},{"cell_type":"markdown","metadata":{"id":"dZEk2uQUMTVf"},"source":["The distribution of `quantity` is very different. We can see that only 4 unique values exist (1, 2, 3, and 4) and they are quite evenly distributed. It seems as though customers are buying in even quantities across 1 to 4 units"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":601},"executionInfo":{"elapsed":498,"status":"ok","timestamp":1651932214058,"user":{"displayName":"Arun Godwin Patel","userId":"00651807189384869925"},"user_tz":-60},"id":"b7BY1OedMQZp","outputId":"6eb5b32f-b022-4258-836f-58084f40b5d9"},"outputs":[],"source":["plot_continuous_distribution(df, 'total')"]},{"cell_type":"markdown","metadata":{"id":"NLLtATfzM7qx"},"source":["The `total` follows a similar distribution to `unit_price`. This you may expect, as the total is calculated as `unit_price x quantity`.\n","\n","However, this distribution is even more positively skewed. Once again, using intuition, this distribution makes sense. You'd expect customers at a grocery store to generally make more transactions of low value and only occasionally make a transaction of a very high value.\n","\n","Now let's turn our attention to the categorical columns within the dataset. \n","\n","Before visualising these columns, it is worth us understanding how many unique values these columns have. If a categorical column has 1000's of unique values, it will be very difficult to visualise.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1651932214065,"user":{"displayName":"Arun Godwin Patel","userId":"00651807189384869925"},"user_tz":-60},"id":"H5ZYUM6BPCPL","outputId":"fd956e8d-fb8f-4dea-e3b0-d2ac66d061bb"},"outputs":[],"source":["get_unique_values(df, 'transaction_id')"]},{"cell_type":"markdown","metadata":{"id":"wFupRXT3PHGQ"},"source":["As explained previously, `transaction_id` is a unique ID column for each transaction. Since each row represents a unique transaction, this means that we have 7829 unique transaction IDs. Therefore, this column is not useful to visualise."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1651932214065,"user":{"displayName":"Arun Godwin Patel","userId":"00651807189384869925"},"user_tz":-60},"id":"irvnAVBfPGge","outputId":"a11d5300-379a-4606-fde8-4c2d0f19f8cf"},"outputs":[],"source":["get_unique_values(df, 'product_id')"]},{"cell_type":"markdown","metadata":{"id":"dylPseJ4Pb4q"},"source":["Similarly, `product_id` is an ID column, however it is unique based on the product that was sold within the transaction. From this computation, we can see that we have 300 unique product IDs, hence 300 unique products within the dataset. This is not worth visualising, but it certainly interesting to know. From the output of the helper function, we can see that the product most frequently was sold within this dataset was `ecac012c-1dec-41d4-9ebd-56fb7166f6d9`, sold 114 times during the week. Whereas the product least sold was `ec0bb9b5-45e3-4de8-963d-e92aa91a201e` sold just 3 times\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1651932214065,"user":{"displayName":"Arun Godwin Patel","userId":"00651807189384869925"},"user_tz":-60},"id":"pvkYDY4nP8b2","outputId":"a38bad50-1ae4-489f-dd87-ea015cfe48a8"},"outputs":[],"source":["get_unique_values(df, 'category')"]},{"cell_type":"markdown","metadata":{"id":"vvjjhm3oP_jS"},"source":["There are 22 unique values for `category`, with `fruit` and `vegetables` being the 2 most frequently purchased product categories and `spices and herbs` being the least. Let's visualise this too"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":311},"executionInfo":{"elapsed":805,"status":"ok","timestamp":1651932214856,"user":{"displayName":"Arun Godwin Patel","userId":"00651807189384869925"},"user_tz":-60},"id":"Y4obzD1WM7OF","outputId":"4842a4fc-cd65-4bed-f487-523b5cdc3acf"},"outputs":[],"source":["plot_categorical_distribution(df, 'category', height=10, aspect=3.5)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1651932214857,"user":{"displayName":"Arun Godwin Patel","userId":"00651807189384869925"},"user_tz":-60},"id":"WrbwaaNLTR8s","outputId":"341e9cbc-84a4-4f09-89ac-2c96d2315a92"},"outputs":[],"source":["get_unique_values(df, 'customer_type')"]},{"cell_type":"markdown","metadata":{"id":"oFR2oP21fCUC"},"source":["There are 5 unique values for `customer_type`, and they seem to be evenly distributed. Let's visualise this:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":385},"executionInfo":{"elapsed":345,"status":"ok","timestamp":1651932215198,"user":{"displayName":"Arun Godwin Patel","userId":"00651807189384869925"},"user_tz":-60},"id":"RuAKpCgFTR29","outputId":"9b30349f-5da9-4cc7-d5b6-89bc138c62bd"},"outputs":[],"source":["plot_categorical_distribution(df, 'customer_type', height=5, aspect=1.5)"]},{"cell_type":"markdown","metadata":{"id":"DZBTfOj4fwV8"},"source":["From this sample of data, non-members appear to be the most frequent type of customers, closely followed by standard and premium customers"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1651932215198,"user":{"displayName":"Arun Godwin Patel","userId":"00651807189384869925"},"user_tz":-60},"id":"YK2fT3hUTRZZ","outputId":"51662af9-ad22-4708-c947-ead992ddea24"},"outputs":[],"source":["get_unique_values(df, 'payment_type')"]},{"cell_type":"markdown","metadata":{"id":"npDIrQNdfb80"},"source":["There are 4 unique values for `payment_type`, and they seem to be quite evenly distributed once again. Let's visualise this:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":385},"executionInfo":{"elapsed":244,"status":"ok","timestamp":1651932215439,"user":{"displayName":"Arun Godwin Patel","userId":"00651807189384869925"},"user_tz":-60},"id":"6HiYMbv5fbKt","outputId":"db6f961d-1b6e-4a4d-c7a1-a979f16f80c3"},"outputs":[],"source":["plot_categorical_distribution(df, 'payment_type', height=5, aspect=1.5)"]},{"cell_type":"markdown","metadata":{"id":"0_fsQ3D0xO9P"},"source":["Interestingly, cash seems to be the most frequently used method of payment from this sample of data, with debit cards being the least frequent. \n","\n","\n","This dataset is a sample from 1 store across 1 week. So it will be interesting to see if the population sample follows similar patterns."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1651932215439,"user":{"displayName":"Arun Godwin Patel","userId":"00651807189384869925"},"user_tz":-60},"id":"JXOB3sdGObUo","outputId":"d1ebc11f-0abd-483b-f42c-05e87fc356a3"},"outputs":[],"source":["get_unique_values(df, 'timestamp')"]},{"cell_type":"markdown","metadata":{"id":"F8PgvrZLyydE"},"source":["Clearly there are a lot of unique values for the timestamp column. \n","\n","However, you may have noticed something...\n","\n","The column named `timestamp` appears to be categorical, but in actual fact it's not. This is a datetime, following the format of `2022-03-01 10:00:45 = YYYY-MM-DD HH:MM:SS`. Therefore, we must transform this column to reflect its true form.\n","\n","A helper function is provided below to convert the column into a datetime column."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OjNsJZXfxkK0"},"outputs":[],"source":["def convert_to_datetime(data: pd.DataFrame = None, column: str = None):\n","\n","  dummy = data.copy()\n","  dummy[column] = pd.to_datetime(dummy[column], format='%Y-%m-%d %H:%M:%S')\n","  return dummy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eRUCmIiszYTz"},"outputs":[],"source":["df = convert_to_datetime(df, 'timestamp')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1651932215706,"user":{"displayName":"Arun Godwin Patel","userId":"00651807189384869925"},"user_tz":-60},"id":"ufnntfrCzfL1","outputId":"b1cdc494-1fec-40ad-fb76-1db9c46daf69"},"outputs":[],"source":["df.info()"]},{"cell_type":"markdown","metadata":{"id":"L8G7sAyYz9qj"},"source":["Using the `.info()` method again, we can see that the timestamp is now of type `datetime64[ns`, which indicates it is a datetime based data type. Now that this is a datetime column, we can explode this column out into its consitituent parts, e.g. we can explode datetime into `hour` for example."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BfJO4bDbz8ZL"},"outputs":[],"source":["df['hour'] = df['timestamp'].dt.hour"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1651932215709,"user":{"displayName":"Arun Godwin Patel","userId":"00651807189384869925"},"user_tz":-60},"id":"mQlTLn8v0pY1","outputId":"50c11941-9b28-40d8-c9ae-17b2dad3d0ce"},"outputs":[],"source":["df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1651932215709,"user":{"displayName":"Arun Godwin Patel","userId":"00651807189384869925"},"user_tz":-60},"id":"yF4H9Cam0qTT","outputId":"05a90e00-1280-4f6e-9a7a-eda5d289539d"},"outputs":[],"source":["get_unique_values(df, 'hour')"]},{"cell_type":"markdown","metadata":{"id":"0iE84kQX0yut"},"source":["From this we can see that the 11th, 16th and 18th hour of the day are the top 3 hours of the day for transactions being processed. This is interesting, this would suggest that their busiest times of day may be just before lunch, and as people are on the way home from work. Once again, this is a small sample of data, so we can't make assumptions on the population sample of data, but it gives us insights to go back to the business with."]},{"cell_type":"markdown","metadata":{"id":"DhUPnd-b1amN"},"source":["---\n","\n","## Section 5 - Correlations\n","\n","By now, you should have a good understanding of all the columns within the dataset, as well as the values that occur within each column. One more thing that we can do is to look at how each of the numerical columns are related to each other.\n","\n","To do this, we can use `correlations`. Correlations measure how each numeric column is linearly related to each other. It is measured between -1 and 1. If a correlation between 2 columns is close to -1, it shows that there is a negative correlation, that is, as 1 increases, the other decreases. If a correlation between 2 columns is close to 1, it shows that they are positively correlated, that is, as 1 increases, so does the other. Therefore, correlations do not infer that one column causes the other, but it gives us an indication as to how the columns are linearly related."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":175},"executionInfo":{"elapsed":293,"status":"ok","timestamp":1651933041993,"user":{"displayName":"Arun Godwin Patel","userId":"00651807189384869925"},"user_tz":-60},"id":"szt_Auyx1E56","outputId":"0aad69cb-6d3e-4f07-8f50-bd7ef4ffca9e"},"outputs":[],"source":["corr = df.corr()\n","corr.style.background_gradient(cmap='coolwarm')"]},{"cell_type":"markdown","metadata":{"id":"oBin5kdG4iS0"},"source":["From this correlation matrix, we can see that the only columns that have a high correlation are `unit_price` and `total`. This is understandable because total is calculated used unit_price. \n","\n","All the other correlations are close to 0, indicating that there is not a significant positive or negative correlation between the numeric variables.\n","\n","---\n","\n","## Section 6 - Summary\n","\n","We have completed an initial exploratory data analysis on the sample of data provided. We should now have a solid understanding of the data. \n","\n","The client wants to know\n","\n","```\n","\"How to better stock the items that they sell\"\n","```\n","\n","From this dataset, it is impossible to answer that question. In order to make the next step on this project with the client, it is clear that:\n","\n","- We need more rows of data. The current sample is only from 1 store and 1 week worth of data\n","- We need to frame the specific problem statement that we want to solve. The current business problem is too broad, we should narrow down the focus in order to deliver a valuable end product\n","- We need more features. Based on the problem statement that we move forward with, we need more columns (features) that may help us to understand the outcome that we're solving for\n","\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMUp+nXmkWPRzOa2DO1gGHm","collapsed_sections":[],"name":"eda_walkthrough","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":0}
